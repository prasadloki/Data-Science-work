# üìä Data Science Course Assignments

Welcome to my Data Science course repository! This repo contains **20 hands-on assignments** that span across the key domains of data science, machine learning, and statistical analysis. Each assignment is a focused learning module covering a specific topic, structured to help reinforce both theoretical understanding and practical implementation.

---

## üìÅ Repository Structure

Each folder in this repository corresponds to a specific assignment. The assignments are named and organized in the order typically followed in a comprehensive Data Science curriculum.

### üìö Assignments Overview

1. **Basic Statistics - Level 1**
   - Introduction to fundamental statistical concepts: mean, median, mode, standard deviation, etc.
   - Includes calculation of descriptive stats using Python.

2. **Basic Statistics - Level 2**
   - Deeper exploration of probability distributions (normal, binomial, Poisson).
   - Central Limit Theorem, Z-scores, confidence intervals.

3. **Basics of Python**
   - Python fundamentals for data science: data types, loops, functions, list comprehensions, libraries (NumPy, Pandas).

4. **Hypothesis Testing**
   - Statistical testing: t-tests, chi-square, ANOVA.
   - Interpreting p-values and making decisions based on test results.

5. **EDA1 (Exploratory Data Analysis - Part 1)**
   - Data cleaning, handling missing values, outlier detection.
   - Visual exploration using Matplotlib and Seaborn.

6. **Multiple Linear Regression (MLR)**
   - Building and evaluating multiple linear regression models.
   - Multicollinearity checks, model interpretation, and residual analysis.

7. **Logistic Regression**
   - Binary classification using logistic regression.
   - ROC curves, AUC, confusion matrix, precision-recall metrics.

8. **Clustering**
   - Unsupervised learning with K-Means and Hierarchical Clustering.
   - Choosing optimal clusters using Elbow Method and Dendrograms.

9. **Principal Component Analysis (PCA)**
   - Dimensionality reduction using PCA.
   - Explained variance and feature transformation.

10. **Association Rules**
    - Market basket analysis using Apriori and FP-Growth.
    - Concepts: support, confidence, lift.

11. **Recommendation System**
    - Building content-based and collaborative filtering recommender systems.
    - Using cosine similarity and matrix factorization.

12. **EDA2 (Exploratory Data Analysis - Part 2)**
    - Advanced visualizations and feature engineering.
    - Correlation analysis, pair plots, and data transformation.

13. **Decision Tree**
    - Building decision tree models for classification and regression.
    - Gini index, entropy, pruning techniques.

14. **Random Forest**
    - Ensemble method using bagging and random decision trees.
    - Feature importance and hyperparameter tuning.

15. **XGBoost & LightGBM**
    - Gradient boosting techniques using XGBoost and LightGBM libraries.
    - Advanced model tuning and early stopping.

16. **K-Nearest Neighbors (KNN)**
    - Distance-based classification and regression.
    - Hyperparameter tuning and feature scaling.

17. **Support Vector Machine (SVM)**
    - Margin-based classifier using linear and kernel-based SVMs.
    - Hyperparameter tuning with GridSearch.

18. **Neural Networks**
    - Introduction to deep learning using MLP (Multi-Layer Perceptrons).
    - Activation functions, forward and backpropagation.

19. **Naive Bayes & Text Mining**
    - Text preprocessing: tokenization, TF-IDF, stop word removal.
    - Spam classification using Naive Bayes algorithm.

20. **Time Series Analysis**
    - Decomposition, stationarity checks, autocorrelation, and ARIMA modeling.
    - Forecasting future trends based on historical data.

---

## üõ†Ô∏è Technologies Used

- Python 3.x
- Jupyter Notebook
- Libraries: `NumPy`, `Pandas`, `Matplotlib`, `Seaborn`, `Scikit-learn`, `XGBoost`, `LightGBM`, `NLTK`, `Statsmodels`

---
